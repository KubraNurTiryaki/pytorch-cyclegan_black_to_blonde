{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b1bddb-b9f7-46ed-9ba7-a2e19cb3576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc5d427-8dea-4888-8180-edf912ebccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation  as animation\n",
    "from IPython.display import HTML , Image as ImgDisplay # burada sorun çıkabilir çıkarsa from IPython.display import Image as ImgDisplay olacak şekilde aşağıya yaz \n",
    "from torchsummary import summary\n",
    "from torchvision.utils import save_image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd319586-60c6-4b54-a8d6-adc745beeda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"./img_align_celeba/img_align_celeba\"\n",
    "attributes_file = \"./list_attr_celeba.csv\"\n",
    "output_dir = \"./preprocessed_dataset_celeba\"\n",
    "\n",
    "data = pd.read_csv(attributes_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0648caa9-cf0b-428f-9b42-c7ea88bcc55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siyah saç özelliği \"1\" olan Kadın ünlülerden 1000 tane örnek seçtik, dataframe'e attık.\n",
    "df_blackHair = data.loc[data[\"Black_Hair\"] == 1 & (data[\"Male\"] == -1)].sample(n = 1000) \n",
    "df_blonde = data.loc[data[\"Blond_Hair\"] == 1 & (data[\"Male\"] == -1)].sample(n = 1000)\n",
    "\n",
    "#Sarı saç özelliği \"1\" olan Kadın ünlülerden 1000 tane örnek seçtik, dataframe'e attık."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6e6dbe-d438-4f97-9024-2a1f1c6b377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "domainK, domainD = [],[]\n",
    "\n",
    "for index, row in df_blackHair.iterrows():\n",
    "    domainK.append(row[\"image_id]\")\n",
    "\n",
    "for index, row in df_blonde.iterrows():\n",
    "    domainK.append(row[\"image_id]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b4572-9811-4565-9183-957eefddc344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ve test verilerini ilk seçtiğimiz 1000'er resimden bölerek oluşturalım.\n",
    "K_train, K_test = train_test_split(domainK, test_size = 0.01, random_state = 1453 )\n",
    "D_train, D_test = train_test_split(domainD, test_size = 0.01, random_state = 1453 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1165585c-5200-4dd5-ba14-488853112101",
   "metadata": {},
   "source": [
    "Eğitim ve test veri seti başka bir yere kaydediliyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a29899-08d2-42cd-8543-d49f2f8ca488",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = min(len(K_train), len(B_train))\n",
    "K_train = K_train[:N]\n",
    "D_train = D_train[:N]\n",
    "print(f\"Images in K(black) {len(K_train)} and D(blonde) {len(D_train)}\")\n",
    "K_train_dir = os.path.join(output_dir, \"train/K\")\n",
    "D_train_dir = os.path.join(output_dir, \"train/D\")\n",
    "\n",
    "os.makedirs(K_train_dir, exist_ok = True)\n",
    "os.makedirs(D_train_dir, exist_ok = True)\n",
    "\n",
    "for imageK, imageD in zip(K_train, D_train):\n",
    "    shutil.copy(os.path.join(image_dir, imageK), os.path.join(K_train_dir, imageK))\n",
    "    shutil.copy(os.path.join(image_dir, imageD), os.path.join(D_train_dir, imageD))\n",
    "\n",
    "#test verisi de eşit olsun\n",
    "N = min(len(K_test), len(D_test))\n",
    "K_test = K_test[:N]\n",
    "D_test = D_test[:N]\n",
    "print(f\"Images in K(black) {len(K_test)} and D(blonde) {len(D_test)}\")\n",
    "\n",
    "K_test_dir = os.path.join(output_dir, \"test/K\")\n",
    "D_test_dir = os.path.join(output_dir, \"test_D\")\n",
    "\n",
    "os.makedirs(K_test_dir, exist_ok = True)\n",
    "os.makedirs(D_test_dir, exist_ok = True)\n",
    "\n",
    "for imageK, imageD in zip(K_test, D_test):\n",
    "    shutil.copy(os.path.join(image_dir, imageK), os.path.join(K_test_dir, imageK))\n",
    "    shutil.copy(os.path.join(image_dir, imageD), os.path.join(D_test_dir, imageD))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35902de4-a5a0-4666-a664-e378d58dc734",
   "metadata": {},
   "source": [
    "DATASET SINIFIMIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fda49e-5fa6-4790-bf79-16dea9216ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, transforms_ = None, unaligned = False, mode = \"train\"):\n",
    "        #gelen transform fonksiyonu kullanılıyoe\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.unaligned = unaligned\n",
    "\n",
    "    self.files_K = sorted(glob.glob(os.path.join(root, \"%s/K\" %mode) + \"/*.*\"))\n",
    "    self.files_D = sorted(glob.glob(os.path.join(root, \"%s/D\" %mode) + \"/*.*\"))\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        #eğitim yapılırken her veri alışında bu fonksiyona giriliyor ve veri ön işlemeden geçiriliyor\n",
    "        item_K = self.transform(Image.open(self.files_K[index % len(self.files_K)]))\n",
    "\n",
    "        if self.unaligned:\n",
    "            # veriler eşli olmadığından dolayı rastgele bir foto seçiliyo\n",
    "            item_D = self.transform(Image.open(self.files_D[random.randint(0, len(self.files_D) - 1)]))\n",
    "        else:\n",
    "            item_D = self.transform(Image.open(self.files_D[index % len(self.files_D)]))\n",
    "\n",
    "        return {\"K(black)\": item_K, \"D(blonde)\": item_D}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_K), len(self.files_D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869725eb-4164-45e7-b5fb-df85415f2f9c",
   "metadata": {},
   "source": [
    "GENERATOR BLOKLARI VE GENERATOR YAPAY SİNİR AĞI TASARIMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24946af2-e3b2-4702-8d7e-d34782b22f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [\n",
    "            \n",
    "        ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
