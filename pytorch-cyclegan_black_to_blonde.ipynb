{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b1bddb-b9f7-46ed-9ba7-a2e19cb3576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af775b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc5d427-8dea-4888-8180-edf912ebccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil #kopyalama için kullanıyoruz\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob     #dosya okuma fonksiyonları\n",
    "import random   #dosya okuma fonksiyonları \n",
    "import os       #dosya okuma fonksiyonları\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tqdm.notebook import tqdm      #eğitim aşamasında nerde olduğumuzu görmek için kullanıyoruz\n",
    "\"\"\"TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
    "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
    "  pbar = tqdm(range(epoch, n_epochs))\"\"\"\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation  as animation\n",
    "from IPython.display import HTML , Image as ImgDisplay # burada sorun çıkabilir çıkarsa from IPython.display import Image as ImgDisplay olacak şekilde aşağıya yaz \n",
    "from torchsummary import summary\n",
    "from torchvision.utils import save_image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd319586-60c6-4b54-a8d6-adc745beeda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"./img_align_celeba/img_align_celeba\"\n",
    "attributes_file = \"./list_attr_celeba.csv\"\n",
    "output_dir = \"./preprocessed_dataset_celeba\"\n",
    "\n",
    "data = pd.read_csv(attributes_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0648caa9-cf0b-428f-9b42-c7ea88bcc55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siyah saç özelliği \"1\" olan Kadın ünlülerden 1000 tane örnek seçtik, dataframe'e attık.\n",
    "df_blackHair = data.loc[data[\"Black_Hair\"] == 1 & (data[\"Male\"] == -1)].sample(n = 1000)\n",
    "\n",
    "#Sarı saç özelliği \"1\" olan Kadın ünlülerden 1000 tane örnek seçtik, dataframe'e attık.\n",
    "df_blonde = data.loc[data[\"Blond_Hair\"] == 1 & (data[\"Male\"] == -1)].sample(n = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6e6dbe-d438-4f97-9024-2a1f1c6b377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seçilen resimlerin isimlerine daha rahat ulaşmak için bir listeye kaydedelim\n",
    "domainK, domainD = [] , []\n",
    "\n",
    "for index, row in df_blackHair.iterrows():\n",
    "    domainK.append(row[\"image_id\"])\n",
    "\n",
    "for index, row in df_blonde.iterrows():\n",
    "    domainD.append(row[\"image_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b4572-9811-4565-9183-957eefddc344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ve test verilerini ilk seçtiğimiz 1000'er resimden bölerek oluşturalım.\n",
    "K_train, K_test = train_test_split(domainK, test_size = 0.01, random_state = 1453 )\n",
    "D_train, D_test = train_test_split(domainD, test_size = 0.01, random_state = 1453 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1165585c-5200-4dd5-ba14-488853112101",
   "metadata": {},
   "source": [
    "Eğitim ve test veri seti başka bir yere kaydediliyor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a29899-08d2-42cd-8543-d49f2f8ca488",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = min(len(K_train), len(D_train))\n",
    "K_train = K_train[:N]\n",
    "D_train = D_train[:N]\n",
    "print(f\"Images in K(black) {len(K_train)} and D(blonde) {len(D_train)}\")\n",
    "K_train_dir = os.path.join(output_dir, \"train/K\")\n",
    "D_train_dir = os.path.join(output_dir, \"train/D\")\n",
    "\n",
    "os.makedirs(K_train_dir, exist_ok = True)\n",
    "os.makedirs(D_train_dir, exist_ok = True)\n",
    "\n",
    "for imageK, imageD in zip(K_train, D_train):\n",
    "    shutil.copy(os.path.join(image_dir, imageK), os.path.join(K_train_dir, imageK))\n",
    "    shutil.copy(os.path.join(image_dir, imageD), os.path.join(D_train_dir, imageD))\n",
    "\n",
    "#test verisi de eşit olsun\n",
    "N = min(len(K_test), len(D_test))\n",
    "K_test = K_test[:N]\n",
    "D_test = D_test[:N]\n",
    "print(f\"Images in K(black) {len(K_test)} and D(blonde) {len(D_test)}\")\n",
    "\n",
    "K_test_dir = os.path.join(output_dir, \"test/K\")\n",
    "D_test_dir = os.path.join(output_dir, \"test_D\")\n",
    "\n",
    "os.makedirs(K_test_dir, exist_ok = True)\n",
    "os.makedirs(D_test_dir, exist_ok = True)\n",
    "\n",
    "for imageK, imageD in zip(K_test, D_test):\n",
    "    shutil.copy(os.path.join(image_dir, imageK), os.path.join(K_test_dir, imageK))\n",
    "    shutil.copy(os.path.join(image_dir, imageD), os.path.join(D_test_dir, imageD))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35902de4-a5a0-4666-a664-e378d58dc734",
   "metadata": {},
   "source": [
    "DATASET SINIFIMIZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fda49e-5fa6-4790-bf79-16dea9216ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, root, transforms_ = None, unaligned = False, mode = \"train\"):    # root = verinin bulunduğu kök klasör\n",
    "        #gelen transform fonksiyonu kullanılıyoe\n",
    "        self.transform = transforms.Compose(transforms_)\n",
    "        self.unaligned = unaligned\n",
    "\n",
    "        self.files_K = sorted(glob.glob(os.path.join(root, \"%s/K\" %mode) + \"/*.*\"))        \n",
    "        self.files_D = sorted(glob.glob(os.path.join(root, \"%s/D\" %mode) + \"/*.*\"))\n",
    "\n",
    "    def __getitem__(self,index):        #eğitim yapılırken her veri alışında bu fonksiyon çalışır yani\n",
    "        #eğitim yapılırken her veri alışında bu fonksiyona giriliyor ve veri ön işlemeden geçiriliyor\n",
    "        item_K = self.transform(Image.open(self.files_K[index % len(self.files_K)]))\n",
    "\n",
    "        if self.unaligned:\n",
    "            # veriler eşli olmadığından dolayı rastgele bir foto seçiliyo\n",
    "            item_D = self.transform(Image.open(self.files_D[random.randint(0, len(self.files_D) - 1)]))\n",
    "        else:\n",
    "            item_D = self.transform(Image.open(self.files_D[index % len(self.files_D)]))\n",
    "\n",
    "        return {\"K(black)\": item_K, \"D(blonde)\": item_D}\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(len(self.files_K), len(self.files_D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869725eb-4164-45e7-b5fb-df85415f2f9c",
   "metadata": {},
   "source": [
    "GENERATOR BLOKLARI VE GENERATOR YAPAY SİNİR AĞI TASARIMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24946af2-e3b2-4702-8d7e-d34782b22f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "\n",
    "        conv_block = [\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_features,in_features,3),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_features,in_features,3),\n",
    "            nn.InstanceNorm2d(in_features)\n",
    "        ]\n",
    "\n",
    "        self.conv_block = nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, n_residual_blocks = 9):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        #Initial convolution block\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(input_nc, 64, 7),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace = True)\n",
    "        ]\n",
    "\n",
    "        #Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features*2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                  nn.Conv2d(in_features,out_features,3, stride = 2, padding = 1),\n",
    "                  nn.InstanceNorm2d(out_features),\n",
    "                  nn.ReLU(inplace = True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features*2\n",
    "\n",
    "        #Residual Blocks\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "\n",
    "        #Upsampling\n",
    "        out_features = in_features//2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                  nn.ConvTranspose2d(in_features,out_features,3, stride = 2, padding = 1, output_padding = 1),\n",
    "                  nn.InstanceNorm2d(out_features),\n",
    "                  nn.ReLU(inplace = True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features//2\n",
    "\n",
    "        #Output LAyer\n",
    "        model += [\n",
    "                  nn.ReflectionPad2d(3),\n",
    "                  nn.Conv2d(64, output_nc, 7),\n",
    "                  nn.Tanh()\n",
    "            ]\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3cc86d",
   "metadata": {},
   "source": [
    "Discriminator Yapay Sinir Ağı Tasarımı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e76b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_nc):\n",
    "        #PatchGAN discriminatorunun yapısı\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "\n",
    "        #A brunch of convolutions one after another\n",
    "        model = [\n",
    "            nn.Conv2d(input_nc, 64 ,4 , stride= 2, padding= 1),\n",
    "            nn.LeakyReLU(0.2, inplace= True)\n",
    "        ]\n",
    "\n",
    "        model += [\n",
    "            nn.Conv2d(64 ,128, 4, stride= 2, padding= 1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace= True)\n",
    "        ]\n",
    "    \n",
    "        model += [\n",
    "            nn.Conv2d(128, 256, 4, stride= 2, padding= 1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace= True)\n",
    "        ]\n",
    "    \n",
    "        model += [\n",
    "            nn.Conv2d(256, 512, 4, stride= 2, padding= 1),\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace= True)\n",
    "        ]\n",
    "    \n",
    "        #FCN classification Layer\n",
    "        model += [nn.Conv2d(512, 1, 4, padding= 1)]\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        #Average pooling and flatten\n",
    "        return F.avg_pool2d(x, x.size()[2:]).view(x.size()[0], -1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c0d4d",
   "metadata": {},
   "source": [
    "EK FONKSİYONLAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50065500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2image(tensor):\n",
    "    #görselleştirmek için gpu'ya atılmış tensor verisi işlemci üzerinde imgeye dönüştürülür.\n",
    "    image = 127.5*(tensor[0].cpu().float().numpy() + 1.0)\n",
    "    if image.shape[0] == 1:\n",
    "        image = nn.tile(image, (3,1,1))\n",
    "    return image.astype(np.uint8)\n",
    "\n",
    "class ReplayBuffer():\n",
    "    #Kayıp hesabı yapılırken Buffer a veri atıp çıkartıyoruz\n",
    "    def __init__(self, max_size = 50):\n",
    "        assert (max_size > 0), \"Empty buffer or trying to create a black hole. Be careful.\"\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data :\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                to_return.append(element)\n",
    "        return Variable(torch.cat(to_return))\n",
    "    \n",
    "class LambdaLR():\n",
    "    #Learning rate decay ayarları burda yapılıyo\n",
    "    def __init__(self, n_epochs, offset, decay_start_epoch):\n",
    "        assert ((n_epochs - decay_start_epoch) > 0 ), \"Decay must start before the trainin session ends!\"\n",
    "        self.n_epochs = n_epochs\n",
    "        self.offset = offset\n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "\n",
    "    def step(self, epoch):\n",
    "        return 1.0 - max(0, epoch, self.offset - self.decay_start_epoch) / (self.n_epochs - self.decay_start_epoch)\n",
    "    \n",
    "def weights_init_normal(m):\n",
    "    #Yapay sinir ağının ağırlıklarının uniform bir dağılımda ilklendirilmesi için bu fonksiyon kullanılıyor.\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        torch.nn.init.constant(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a740fae9",
   "metadata": {},
   "source": [
    "Eğitim parametreleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc02e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "n_epochs = 50\n",
    "batchSize = 1\n",
    "dataraoot = \"./preprocessed_dataset_celeba\"\n",
    "lr = 0.0002\n",
    "decay_epoch = 3\n",
    "size = 256\n",
    "input_nc = 3\n",
    "output_nc = 3\n",
    "cuda = True\n",
    "n_cpu = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d2673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available() and not cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")\n",
    "\n",
    "\n",
    "##### Definition of variables #####\n",
    "#Networks\n",
    "netG_K2D = Generator(input_nc, output_nc)\n",
    "netG_D2K = Generator(output_nc, input_nc)\n",
    "netD_K = Discriminator(input_nc)\n",
    "netD_D = Discriminator(output_nc)\n",
    "\n",
    "if cuda :\n",
    "     netG_D2K.cuda()\n",
    "     netG_K2D.cuda()\n",
    "     netD_K.cuda()\n",
    "     netD_D.cuda()\n",
    "\n",
    "netG_K2D.apply(weights_init_normal)\n",
    "netG_D2K.apply(weights_init_normal)\n",
    "netD_K.apply(weights_init_normal)\n",
    "netD_D.apply(weights_init_normal)\n",
    "\n",
    "#Losses\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "criterion_identity = torch.nn.L1Loss()\n",
    "\n",
    "\n",
    "#Optimizers & LR schedulers\n",
    "optimizer_G = torch.optim.Adam(itertools.chain(netG_K2D.parameters(), netG_D2K.parameters()),\n",
    "                               lr = lr, betas = (0.5, 0.999))\n",
    "optimizerD_K = torch.optim.Adam(netD_K.parameters(), lr = lr, betas = (0.5, 0.999))\n",
    "optimizerD_D = torch.optim.Adam(netD_D.parameters(), lr = lr, betas = (0.5, 0.999))\n",
    "\n",
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda = LambdaLR(n_epochs, epoch, decay_epoch).step)\n",
    "lr_schedulerD_K = torch.optim.lr_scheduler.LambdaLR(optimizerD_K, lr_lambda = LambdaLR(n_epochs, epoch, decay_epoch).step)\n",
    "lr_schedulerD_D = torch.optim.lr_scheduler.LambdaLR(optimizerD_D, lr_lambda = LambdaLR(n_epochs, epoch, decay_epoch).step)\n",
    "\n",
    "#Inputs & targets memory alloc\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor\n",
    "input_K = Tensor(batchSize, input_nc, size, size)\n",
    "input_D = Tensor(batchSize, input_nc, size, size)\n",
    "target_real = Variable(Tensor(batchSize,1). fill_(1.0), requires_grad = False)\n",
    "target_fake = Variable(Tensor(batchSize,1). fill_(0.0), requires_grad = False)\n",
    "\n",
    "fake_K_buffer = ReplayBuffer()\n",
    "fake_D_buffer = ReplayBuffer()\n",
    "\n",
    "#Dataset Loader\n",
    "transforms_ = [\n",
    "     transforms.Resize(int(size*1.12), Image.BICUBIC),\n",
    "     transforms.RandomCrop(size),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "]\n",
    "\n",
    "dataloader = DataLoader(ImageDataset(dataraoot, transforms_=transforms_, unaligned= True),\n",
    "                        batch_size = batchSize, shuffle = True, num_workers = n_cpu)\n",
    "\n",
    "G_loss = []\n",
    "G_identity_loss = []\n",
    "G_gan_loss = []\n",
    "G_cycle_loss = []\n",
    "D_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0fabee",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Training #####\n",
    "pbar = tqdm(range(epoch, n_epochs))\n",
    "for epoch in pbar :\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        #Set model input\n",
    "        real_K = Variable(input_K.copy_(batch[\"K\"]))\n",
    "        real_D = Variable(input_D.copy_(batch[\"D\"]))\n",
    "\n",
    "        ##### Generators K2D and D2K #####\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        #Identity loss\n",
    "        #G_K2D(D) should D if real D is fed\n",
    "        same_D = netG_K2D(real_K)\n",
    "        loss_identity_D = criterion_identity(same_D, real_D)*5.0\n",
    "        #G_D2K(K) should K if real K is fed\n",
    "        same_K = netG_D2K(real_D)\n",
    "        loss_identity_K = criterion_identity(same_K, real_K)*5.0\n",
    "\n",
    "        #GAN Loss\n",
    "        fake_D = netG_K2D(real_K)\n",
    "        pred_fake = netD_D(fake_D)\n",
    "        loss_GAN_K2D = criterion_GAN(pred_fake, target_real)\n",
    "        \n",
    "        fake_K = netG_D2K(real_D)\n",
    "        pred_fake = netD_K(fake_K)\n",
    "        loss_GAN_D2K = criterion_GAN(pred_fake, target_real)\n",
    "\n",
    "        #Cycle Loss\n",
    "        recovered_K = netG_D2K(fake_D)\n",
    "        loss_cycle_KDK = criterion_cycle(recovered_K, real_K)*10.0\n",
    "\n",
    "        recovered_D = netG_K2D(fake_K)        \n",
    "        loss_cycle_DKD = criterion_cycle(recovered_D, real_D)*10.0\n",
    "\n",
    "        #Total loss\n",
    "        loss_G = loss_identity_K + loss_identity_D + loss_GAN_D2K + loss_GAN_K2D + loss_cycle_KDK + loss_cycle_DKD\n",
    "        loss_G.backward()\n",
    "\n",
    "        optimizer_G.step()\n",
    "\n",
    "        ################################################\n",
    "\n",
    "        ######## Discriminator K ########\n",
    "        optimizerD_K.zero_grad()\n",
    "\n",
    "        #Real loss\n",
    "        pred_real = netD_K(real_K)\n",
    "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "        #Fake loss\n",
    "        fake_K = fake_K_buffer.push_and_pop(fake_K)\n",
    "        pred_fake = netD_K(fake_K.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "        #Total loss\n",
    "        loss_D_K = (loss_D_real + loss_D_fake)*0.5\n",
    "        loss_D_K.backward()\n",
    "\n",
    "        optimizerD_K.step()\n",
    "\n",
    "        ################################################\n",
    "\n",
    "        ######## Discriminator D ########\n",
    "        optimizerD_D.zero_grad()\n",
    "\n",
    "        #Real loss\n",
    "        pred_real = netD_D(real_D)\n",
    "        loss_D_real = criterion_GAN(pred_real, target_real)\n",
    "\n",
    "        #Fake loss\n",
    "        fake_D = fake_D_buffer.push_and_pop(fake_D)\n",
    "        pred_fake = netD_D(fake_D.detach())\n",
    "        loss_D_fake = criterion_GAN(pred_fake, target_fake)\n",
    "\n",
    "        #Total loss\n",
    "        loss_D_D = (loss_D_real + loss_D_fake)*0.5\n",
    "        loss_D_D.backward()\n",
    "\n",
    "        optimizerD_D.step()\n",
    "\n",
    "        ################################################        \n",
    "\n",
    "\n",
    "        pbar.set_postfix({\"loss_G\": loss_G.item(),\n",
    "                          \"loss_G_cycle\": (loss_cycle_KDK .item() + loss_cycle_DKD.item()), \n",
    "                          \"loss_D\":(loss_D_K.item() + loss_D_D.item())})\n",
    "        G_loss.append(loss_G.item())\n",
    "        G_identity_loss.append(loss_identity_K.item() + loss_identity_D.item())\n",
    "        G_gan_loss.append(loss_GAN_K2D.item() + loss_GAN_D2K.item())\n",
    "        G_cycle_loss.append(loss_cycle_KDK.item() + loss_cycle_DKD.item())\n",
    "        D_loss.append(loss_D_K.item() + loss_D_D.item())\n",
    "\n",
    "    # Update learning rates\n",
    "    lr_scheduler_G.step()\n",
    "    lr_schedulerD_K.step()\n",
    "    lr_schedulerD_D.step()\n",
    "\n",
    "    #Save models checkpoints\n",
    "    torch.save(netG_K2D.state_dict(), \"output/netG_K2D.pth\")\n",
    "    torch.save(netG_D2K.state_dict(), \"output/netG_D2K.pth\")\n",
    "    torch.save(netD_K.state_dict(), \"output/netD_K.pth\")\n",
    "    torch.save(netD_D.state_dict(), \"output/netD_D.pth\")\n",
    "\n",
    "################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bbfc96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
